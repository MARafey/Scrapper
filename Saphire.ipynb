{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-04T18:00:42.230589Z",
     "start_time": "2024-07-04T18:00:41.355871Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import requests as req\n",
    "from bs4 import BeautifulSoup as bsp\n",
    "import pandas as pd\n",
    "import time\n",
    "from selenium import webdriver\n",
    "import requests\n",
    "from selenium.webdriver.edge.service import Service as EdgeService\n",
    "from selenium.webdriver.edge.options import Options as EdgeOptions"
   ],
   "id": "1441d1fbd551d01c",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-04T18:00:42.246773Z",
     "start_time": "2024-07-04T18:00:42.231496Z"
    }
   },
   "cell_type": "code",
   "source": [
    "info = {  # uninitialized dictionary to use for later\n",
    "        'Name': [],\n",
    "        'Price': [],\n",
    "        'Image': [],\n",
    "        'Link':[]\n",
    "    }"
   ],
   "id": "5ff0f61eaa57c96f",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-04T18:00:42.262114Z",
     "start_time": "2024-07-04T18:00:42.248089Z"
    }
   },
   "cell_type": "code",
   "source": "url = 'https://pk.sapphireonline.pk/'",
   "id": "e7f3189e0b647f28",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-04T18:00:43.594901Z",
     "start_time": "2024-07-04T18:00:42.263124Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Getting the navbar of the website\n",
    "soup = bsp(req.get(url).content, 'html.parser')\n",
    "# getting the navbar of the website which has a ul tag with class 't4s-nav__ul t4s-d-inline-flex t4s-flex-wrap t4s-align-items-center'\n",
    "navbar = soup.find('ul', class_='t4s-nav__ul t4s-d-inline-flex t4s-flex-wrap t4s-align-items-center')\n",
    "# In the ul there are li tag each tag has a href in the a tag\n",
    "links = [link.find('a')['href'] for link in navbar.find_all('li')]\n",
    "# adding the url to the links\n",
    "links = [url + link for link in links]\n",
    "\n",
    "for link in links:\n",
    "    print(link)"
   ],
   "id": "c4e0b4dbf526724c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://pk.sapphireonline.pk//collections/new-in\n",
      "https://pk.sapphireonline.pk//collections/woman\n",
      "https://pk.sapphireonline.pk//collections/man\n",
      "https://pk.sapphireonline.pk//collections/kids\n",
      "https://pk.sapphireonline.pk//collections/beauty\n",
      "https://pk.sapphireonline.pk//collections/accessories\n",
      "https://pk.sapphireonline.pk//collections/home\n",
      "https://pk.sapphireonline.pk//pages/the-edit \n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-04T18:00:43.610201Z",
     "start_time": "2024-07-04T18:00:43.596765Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def get_valid_proxies():\n",
    "    proxy_list_url = 'https://free-proxy-list.net/'\n",
    "    response = requests.get(proxy_list_url)\n",
    "    soup = bsp(response.text, 'html.parser')\n",
    "    proxy_data = []\n",
    "    rows = soup.find_all('tr')[1:]\n",
    "    for row in rows:\n",
    "        columns = row.find_all('td')\n",
    "        if len(columns) >= 8:\n",
    "            ip_address = columns[0].text.strip()\n",
    "            google_enabled = columns[5].text.strip().lower() == 'yes'\n",
    "            https_enabled = columns[6].text.strip().lower() == 'yes'\n",
    "            last_checked = columns[7].text.strip()\n",
    "            if (last_checked.endswith('mins ago') and int(last_checked.split(' ')[0]) < 15) or last_checked.endswith('hours ago'):\n",
    "                if google_enabled or https_enabled:\n",
    "                    proxy_data.append({'ip_address': ip_address, 'google_enabled': google_enabled, 'https_enabled': https_enabled})\n",
    "\n",
    "    return proxy_data\n",
    "\n",
    "def rotate_user_agent(proxy):\n",
    "    if proxy:\n",
    "        headers = {\n",
    "            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3',\n",
    "            'http': f'http://{proxy}',\n",
    "            'https': f'https://{proxy}'\n",
    "        }\n",
    "    else:\n",
    "        headers = {\n",
    "            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3'\n",
    "        }\n",
    "    return headers"
   ],
   "id": "3bf930979677527d",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-04T18:11:44.210269Z",
     "start_time": "2024-07-04T18:00:43.612756Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Scrapping the links one by one\n",
    "for link in links:\n",
    "    # Getting the navbar of the website\n",
    "    response = req.get(link)\n",
    "    if not response.ok:\n",
    "        print(\"Server responded with exit code:\", response.status_code) # if scrapping is not allowed\n",
    "    else:\n",
    "        soup = bsp(response.content, 'html.parser')\n",
    "        # scrolling the page to the bottom above the footer then back up to load all the items until the end\n",
    "        edge_options = EdgeOptions()\n",
    "        edge_options.use_chromium = True\n",
    "        edge_options.add_argument(\"--start-maximized\")\n",
    "        driver = webdriver.Edge(service=EdgeService(), options=edge_options)\n",
    "        driver.get(link)\n",
    "        Previous_Height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "        while True:\n",
    "            # go to the bottom of the page to load all the items\n",
    "            driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "            time.sleep(2) # wait for 2 seconds\n",
    "            New_Height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "            if New_Height == Previous_Height:\n",
    "                break\n",
    "            Previous_Height = New_Height\n",
    "            \n",
    "\n",
    "\n",
    "        # getting the html content of the page\n",
    "        html = driver.page_source\n",
    "        driver.quit()\n",
    "        # parsing the html content\n",
    "        soup = bsp(html, 'html.parser')\n",
    "        pretty = soup.prettify() # increasing readability\n",
    "        with open('scrapped.html', 'w', encoding='utf-8') as htmlFile:  # specify encoding method\n",
    "            htmlFile.write(pretty)\n",
    "\n",
    "\n",
    "        # getting the div with class 't4s-section-inner t4s_nt_se_template--16016591585354__main t4s_se_template--16016591585354__main t4s-container-fluid'\n",
    "        products = soup.find('div', class_='t4s-section-inner t4s_nt_se_template--16016591585354__main t4s_se_template--16016591585354__main t4s-container-fluid').find('div', class_='t4s-row').find_all('div', class_='t4s-product t4s-pr-grid t4s-pr-style1 t4s-pr-7738123616330 t4s-col-item is-t4s-pr-created')\n",
    "        \n",
    "        for product in products:\n",
    "            # getting the href from div with class 't4s-product-btns t4s-col-2 t4s-col-lg-5'\n",
    "            link = product.find('div', class_='t4s-product-btns t4s-col-2 t4s-col-lg-5').find('a')['href']\n",
    "            # getting name in h3 tag of class 't4s-product-title'\n",
    "            name = product.find('h3', class_='t4s-product-title').text.strip()\n",
    "            # getting price from div with class 't4s-product-price'\n",
    "            price = product.find('div', class_='t4s-product-price').text.strip()\n",
    "            # getting image from div with class 't4s-product-img t4s_ratio is-show-img2'\n",
    "            image = product.find('div', class_='t4s-product-img t4s_ratio is-show-img2').find('img')['src']\n",
    "            \n",
    "            info['Name'].append(name)\n",
    "            info['Price'].append(price)\n",
    "            info['Image'].append(url+image)\n",
    "            info['Link'].append(url+link)"
   ],
   "id": "4ace64d7d72f6f52",
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'find'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[6], line 38\u001B[0m\n\u001B[0;32m     34\u001B[0m     htmlFile\u001B[38;5;241m.\u001B[39mwrite(pretty)\n\u001B[0;32m     37\u001B[0m \u001B[38;5;66;03m# getting the div with class 't4s-section-inner t4s_nt_se_template--16016591585354__main t4s_se_template--16016591585354__main t4s-container-fluid'\u001B[39;00m\n\u001B[1;32m---> 38\u001B[0m products \u001B[38;5;241m=\u001B[39m \u001B[43msoup\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfind\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mdiv\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mclass_\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mt4s-section-inner t4s_nt_se_template--16016591585354__main t4s_se_template--16016591585354__main t4s-container-fluid\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfind\u001B[49m(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdiv\u001B[39m\u001B[38;5;124m'\u001B[39m, class_\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mt4s-row\u001B[39m\u001B[38;5;124m'\u001B[39m)\u001B[38;5;241m.\u001B[39mfind_all(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdiv\u001B[39m\u001B[38;5;124m'\u001B[39m, class_\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mt4s-product t4s-pr-grid t4s-pr-style1 t4s-pr-7738123616330 t4s-col-item is-t4s-pr-created\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m     40\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m product \u001B[38;5;129;01min\u001B[39;00m products:\n\u001B[0;32m     41\u001B[0m     \u001B[38;5;66;03m# getting the href from div with class 't4s-product-btns t4s-col-2 t4s-col-lg-5'\u001B[39;00m\n\u001B[0;32m     42\u001B[0m     link \u001B[38;5;241m=\u001B[39m product\u001B[38;5;241m.\u001B[39mfind(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdiv\u001B[39m\u001B[38;5;124m'\u001B[39m, class_\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mt4s-product-btns t4s-col-2 t4s-col-lg-5\u001B[39m\u001B[38;5;124m'\u001B[39m)\u001B[38;5;241m.\u001B[39mfind(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124ma\u001B[39m\u001B[38;5;124m'\u001B[39m)[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mhref\u001B[39m\u001B[38;5;124m'\u001B[39m]\n",
      "\u001B[1;31mAttributeError\u001B[0m: 'NoneType' object has no attribute 'find'"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-04T18:13:58.140324Z",
     "start_time": "2024-07-04T18:13:58.133247Z"
    }
   },
   "cell_type": "code",
   "source": "print(info)",
   "id": "4949a9794903328e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Name': [], 'Price': [], 'Image': [], 'Link': []}\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-04T18:11:44.215278Z",
     "start_time": "2024-07-04T18:11:44.213158Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Write dictionary to CSV file\n",
    "df = pd.DataFrame(info)\n",
    "df.to_csv('Sapphire.csv')"
   ],
   "id": "eb9aca907f9838eb",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
